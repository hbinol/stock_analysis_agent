{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbinol/stock_analysis_agent/blob/main/deepseek_AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running Ollama on Google Colab and using LLM models for free\n",
        "In this short tutorial we will discuss how we can harness the powers of Large Language Models (LLMs) without buying expensive laptops, computers and without burning a hole in your pocket.\n",
        "\n",
        "Ollama makes it possible to leverage powerful large language models (LLMs) like mistral, llama3:2, deepseek-r1:7b etc. without needing a powerful expensive compute machine.\n",
        "\n",
        "Google Colabâ€™s provides a cloud environment perfectly suited for running these resource-intensive models. This guide meticulously details setting up and running Ollama on the free version of Google Colab, allowing you to explore the capabilities of LLMs without burning a hole in your pocket.\n",
        "\n",
        "Steps needed to get Ollama up and running on Google Colab\n",
        "Without wasting much time lets dive into the steps we need to perform to harness power of LLMs.\n",
        "\n",
        "# Step 1: Install Packages\n",
        "Installing and load modules in google colab notebook\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "!pip install colab-xterm #this will install colab-xterm\n",
        "%load_ext colabxterm\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Open terminal\n",
        "After installing now we need to open terminal to access command line on google colab\n",
        "\n",
        "\n",
        "\n",
        "```sh\n",
        "%xterm\n",
        "```\n",
        "\n",
        "\n",
        "A terminal will open and you will see something similar in your notebook\n",
        "\n",
        "\n",
        "Step 3: Install ollama\n",
        "Run below command on the terminal to install Ollama\n",
        "\n",
        "```sh\n",
        "curl -fsSL https://ollama.com/install.sh | sh\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Step 4: Pull the desired model\n",
        "Ollama supports quiet a few models and a list of these can be found on there official website at below address: https://ollama.com/library Please type below command in the terminal\n",
        "\n",
        "```sh\n",
        "ollama serve & ollama pull deepseek-r1:7b\n",
        "```"
      ],
      "metadata": {
        "id": "vd-5DtkO17rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "D-fF_r2Hsqq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "voXyntWeupnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S1JhFkh_16Kj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n--pqO78kYj7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langgraph yfinance langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Tuple, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "import json\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import AgentExecutor, Tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import Graph, StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "kkwD6AD8kzBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "    symbol: str\n",
        "    llm: ChatOpenAI\n",
        "    results: Dict"
      ],
      "metadata": {
        "id": "4LL3MACCpf10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ollama endpoint\n",
        "def setup_llm():\n",
        "    return ChatOpenAI(\n",
        "        model=\"deepseek-r1:7b\",\n",
        "        api_key=\"ollama\",\n",
        "        base_url=\"http://127.0.0.1:11434/v1\",\n",
        "        temperature=0,\n",
        "        top_p=0.7\n",
        "    )"
      ],
      "metadata": {
        "id": "woBumli9ldw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Technical Analysis Node\n",
        "def technical_analysis(state: State) -> State:\n",
        "    \"\"\"Node for technical analysis\"\"\"\n",
        "    symbol = state[\"symbol\"]\n",
        "    llm = state[\"llm\"]\n",
        "\n",
        "    # Fetch technical data\n",
        "    stock = yf.Ticker(symbol)\n",
        "    hist = stock.history(period='6mo') # 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd\n",
        "\n",
        "    # Calculate indicators\n",
        "    sma_20 = hist['Close'].rolling(window=20).mean()\n",
        "    sma_50 = hist['Close'].rolling(window=50).mean()\n",
        "    rsi = calculate_rsi(hist['Close'])\n",
        "\n",
        "    data = {\n",
        "        'current_price': hist['Close'].iloc[-1],\n",
        "        'sma_20': sma_20.iloc[-1],\n",
        "        'sma_50': sma_50.iloc[-1],\n",
        "        'rsi': rsi.iloc[-1],\n",
        "        'volume_trend': hist['Volume'].iloc[-5:].mean() / hist['Volume'].iloc[-20:].mean()\n",
        "    }\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Analyze these technical indicators for {symbol}:\n",
        "        {data}\n",
        "\n",
        "        Provide:\n",
        "        1. Trend analysis\n",
        "        2. Support/Resistance levels\n",
        "        3. Technical rating (Bullish/Neutral/Bearish)\n",
        "        4. Key signals\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    analysis = chain.run(symbol=symbol, data=json.dumps(data, indent=2))\n",
        "\n",
        "    state[\"results\"][\"technical\"] = {\n",
        "        \"data\": data,\n",
        "        \"analysis\": analysis\n",
        "    }\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "c5xSskBMlsnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Market Analysis Node\n",
        "def market_analysis(state: State) -> State:\n",
        "    \"\"\"Node for market analysis\"\"\"\n",
        "    symbol = state[\"symbol\"]\n",
        "    llm = state[\"llm\"]\n",
        "\n",
        "    # Fetch market data\n",
        "    stock = yf.Ticker(symbol)\n",
        "    info = stock.info\n",
        "\n",
        "    data = {\n",
        "        'sector': info.get('sector', 'Unknown'),\n",
        "        'industry': info.get('industry', 'Unknown'),\n",
        "        'market_cap': info.get('marketCap', 0),\n",
        "        'beta': info.get('beta', 1.0),\n",
        "        'pe_ratio': info.get('trailingPE', 0)\n",
        "    }\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Analyze the market context for {symbol}:\n",
        "        {data}\n",
        "\n",
        "        Provide:\n",
        "        1. Market sentiment\n",
        "        2. Sector analysis\n",
        "        3. Risk assessment\n",
        "        4. Market outlook\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    analysis = chain.run(symbol=symbol, data=json.dumps(data, indent=2))\n",
        "\n",
        "    state[\"results\"][\"market\"] = {\n",
        "        \"data\": data,\n",
        "        \"analysis\": analysis\n",
        "    }\n",
        "    return state\n",
        "\n",
        "# News Analysis Node\n",
        "def news_analysis(state: State) -> State:\n",
        "    \"\"\"Node for news analysis\"\"\"\n",
        "    symbol = state[\"symbol\"]\n",
        "    llm = state[\"llm\"]\n",
        "\n",
        "    # Fetch news\n",
        "    stock = yf.Ticker(symbol)\n",
        "    news = stock.news[:5]  # Last 5 news items\n",
        "\n",
        "    news_data = [{\n",
        "        'title': item.get('title', ''),\n",
        "        'publisher': item.get('publisher', ''),\n",
        "        'timestamp': datetime.fromtimestamp(item.get('providerPublishTime', 0)).strftime('%Y-%m-%d')\n",
        "    } for item in news]\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Analyze these recent news items for {symbol}:\n",
        "        {news}\n",
        "\n",
        "        Provide:\n",
        "        1. Overall sentiment\n",
        "        2. Key developments\n",
        "        3. Potential impact\n",
        "        4. Risk factors\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    analysis = chain.run(symbol=symbol, news=json.dumps(news_data, indent=2))\n",
        "\n",
        "    state[\"results\"][\"news\"] = {\n",
        "        \"data\": news_data,\n",
        "        \"analysis\": analysis\n",
        "    }\n",
        "    return state\n",
        "\n",
        "# Final Recommendation Node\n",
        "def generate_recommendation(state: State) -> State:\n",
        "    \"\"\"Node for final recommendation\"\"\"\n",
        "    symbol = state[\"symbol\"]\n",
        "    llm = state[\"llm\"]\n",
        "    results = state[\"results\"]\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Based on the following analyses for {symbol}, provide a final recommendation:\n",
        "\n",
        "        Technical Analysis:\n",
        "        {technical}\n",
        "\n",
        "        Market Analysis:\n",
        "        {market}\n",
        "\n",
        "        News Analysis:\n",
        "        {news}\n",
        "\n",
        "        Provide:\n",
        "        1. Final recommendation (Strong Buy/Buy/Hold/Sell/Strong Sell)\n",
        "        2. Confidence score (1-10)\n",
        "        3. Key reasons\n",
        "        4. Risk factors\n",
        "        5. Target price range\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    final_recommendation = chain.run(\n",
        "        symbol=symbol,\n",
        "        technical=results[\"technical\"][\"analysis\"],\n",
        "        market=results[\"market\"][\"analysis\"],\n",
        "        news=results[\"news\"][\"analysis\"]\n",
        "    )\n",
        "\n",
        "    state[\"results\"][\"recommendation\"] = final_recommendation\n",
        "    return state\n",
        "\n",
        "def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "    \"\"\"Calculate RSI indicator\"\"\"\n",
        "    delta = prices.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def create_analysis_graph() -> Graph:\n",
        "    \"\"\"Create the analysis workflow graph\"\"\"\n",
        "    # Create workflow graph\n",
        "    workflow = StateGraph(State)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"technical\", technical_analysis)\n",
        "    workflow.add_node(\"market\", market_analysis)\n",
        "    workflow.add_node(\"news\", news_analysis)\n",
        "    workflow.add_node(\"recommendation\", generate_recommendation)\n",
        "\n",
        "    # Define edges\n",
        "    workflow.add_edge(\"technical\", \"market\")\n",
        "    workflow.add_edge(\"market\", \"news\")\n",
        "    workflow.add_edge(\"news\", \"recommendation\")\n",
        "    workflow.add_edge(START, \"technical\")\n",
        "\n",
        "    # Set end node\n",
        "    workflow.add_edge(\"recommendation\", END)\n",
        "\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "class StockAdvisor:\n",
        "    def __init__(self):\n",
        "        self.llm = setup_llm()\n",
        "        self.graph = create_analysis_graph()\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Dict:\n",
        "        \"\"\"Run complete stock analysis\"\"\"\n",
        "        print(f\"\\nAnalyzing {symbol}...\")\n",
        "\n",
        "        # Initialize state\n",
        "        init_sate: State = {\n",
        "            \"symbol\": symbol,\n",
        "            \"llm\": self.llm,\n",
        "            \"results\": {}\n",
        "        }\n",
        "\n",
        "        # Run analysis\n",
        "        final_state = self.graph.invoke(init_sate)\n",
        "        return final_state[\"results\"]\n",
        "\n",
        "# Helper function to run analysis\n",
        "def run_analysis(symbol: str):\n",
        "    \"\"\"Run stock analysis and print results\"\"\"\n",
        "    advisor = StockAdvisor()\n",
        "    results = advisor.analyze_stock(symbol)\n",
        "\n",
        "    print(f\"\\n=== Stock Analysis Report for {symbol} ===\")\n",
        "\n",
        "    print(\"\\n=== Technical Analysis ===\")\n",
        "    print(results[\"technical\"][\"analysis\"])\n",
        "\n",
        "    print(\"\\n=== Market Analysis ===\")\n",
        "    print(results[\"market\"][\"analysis\"])\n",
        "\n",
        "    print(\"\\n=== News Analysis ===\")\n",
        "    print(results[\"news\"][\"analysis\"])\n",
        "\n",
        "    print(\"\\n=== Final Recommendation ===\")\n",
        "    print(results[\"recommendation\"])\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "GfvtVtwIlAvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(create_analysis_graph().get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "xdNfDUmYzunT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "results = run_analysis(\"AAPL\")"
      ],
      "metadata": {
        "id": "Gbc7cvN2mEdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqJ9snrbIYRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}